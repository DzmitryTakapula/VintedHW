{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputTaskN1:\n",
    "    def __init__(self,data_dir,out_file_name):\n",
    "        \n",
    "        self.data_dir=data_dir # path 2 \"data\" folder\n",
    "        self.input_dir=data_dir+'\\\\data\\\\clicks\\\\' \n",
    "        self.output_dir=data_dir+'\\\\data\\\\'+ out_file_name \n",
    "    \n",
    "    def udf_map(self,file_name,df_obj):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            key: file_name - txt - name of the file in folder (i.e. 'part-004.csv')\n",
    "                \n",
    "            value: df_obj -  DataFrame object - generated from \"file_name\" csv file  \n",
    "        \n",
    "        Output: DataFrame object with key column 'date' consisting of lists ['some-date'] and value column 'index'  consisting of '1' strings\n",
    "        \"\"\"\n",
    "       \n",
    "        df_obj['date']=df_obj['date'].map(lambda x: [x]) # each date in column -> [date] according to MapReduceSmpl spec\n",
    "        \n",
    "        df_obj['index'] = \"1\" \n",
    "        \n",
    "        return df_obj[['date','index']]\n",
    "    \n",
    "    def udf_reduce(self, list_of_vals, list_of_index):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        key: list_of_vals - txt - python list text representation (['13.12.2017'] or '['13.12.2017', 4, 'ad']')\n",
    "        value: list_of_index -  list - list of strings '1' \n",
    "        \n",
    "        Output: list key appended by sum of \"values\"\n",
    "        \"\"\"\n",
    "        list_of_vals=eval(list_of_vals) #converts string to the python list\n",
    "\n",
    "        s=sum([int(i) for i in list_of_index])\n",
    "        \n",
    "        list_of_vals.append(str(s))\n",
    "\n",
    "        return  list_of_vals\n",
    "    \n",
    "    \n",
    "\n",
    "class InputTaskN2(InputTaskN1):\n",
    "    \n",
    "    def __init__(self,data_dir,out_file_name):\n",
    "        \n",
    "        super().__init__(data_dir,out_file_name)\n",
    "        \n",
    "    \n",
    "    def udf_map(self,file_name,df_obj):\n",
    "        \n",
    "        \"\"\"\n",
    "        Input:\n",
    "            key: file_name - txt - name of the file in folder (i.e. 'part-004.csv')\n",
    "                \n",
    "            value: df_obj -  DataFrame object - generated from \"file_name\" csv file  \n",
    "        \n",
    "        Output: DataFrame object with key column consisting of lists of click attributes belonging to LT region and value 'index'  consisting of '1' strings\n",
    "        \"\"\"\n",
    "        \n",
    "        users_dir=self.data_dir+'\\\\data\\\\users\\\\'\n",
    "        \n",
    "        in_files=[users_dir + i for i in os.listdir(users_dir)]\n",
    "        \n",
    "        ids= pandas.concat(map(lambda x: pandas.read_csv(x,delimiter=\";\",header=1,usecols=['id','country']), in_files),ignore_index=True)\n",
    "        \n",
    "        ids=ids[ids['country']=='LT']        \n",
    "\n",
    "        df_obj=df_obj[['date','user_id','click_target']]\n",
    "        df_obj=df_obj[df_obj['user_id'].isin(ids['id'])]\n",
    "       \n",
    "        df_obj=pandas.DataFrame({0: df_obj.values.tolist()})\n",
    "        df_obj['index'] = \"1\"\n",
    "        \n",
    "        return df_obj\n",
    "\n",
    "    \n",
    "class MapReduceSimple:\n",
    "    \n",
    "    def __init__(self, io):\n",
    "\n",
    "        self.io=io # loading  map and reduce functions\n",
    "        \n",
    "        self.prepare_files() #prepare iput files list and erases Intermediate.csv\n",
    "        \n",
    "        self.run_map_threads() # run threads corresponding to each input data file\n",
    "\n",
    "        self.reduce_and_write() # reads from Intermediate.csv, do reduce and write to output \n",
    "        \n",
    "\n",
    "    def prepare_files (self):\n",
    "        \n",
    "        self.in_files=[self.io.input_dir+ i for i in os.listdir(self.io.input_dir)] #list of input files\n",
    "        \n",
    "        self.intm_file=self.io.data_dir+'\\\\data\\\\Intermediate.csv' #  intermediate file\n",
    "        \n",
    "        if os.path.isfile(self.intm_file): os.remove(self.intm_file)  # remove historical records\n",
    "\n",
    "    \n",
    "    def apply_map (self,file_name):\n",
    "        \n",
    "        df = pandas.read_csv(file_name,delimiter=\";\",header=1)\n",
    "        \n",
    "        df=self.io.udf_map(file_name,df)\n",
    "\n",
    "        df.to_csv(self.intm_file,index=False,mode='a',sep=';',header=False)\n",
    "        \n",
    "        \n",
    "    def run_map_threads (self):\n",
    "        \n",
    "        map_threads_obj=list(map(lambda s: Thread(target=self.apply_map, args=(s,)), self.in_files)) # run Threads for each file\n",
    "        \n",
    "        map_threads_start=list(map(lambda s: s.start(),map_threads_obj))\n",
    "        \n",
    "        map_threads_join=list(map(lambda s: s.join(),map_threads_obj))\n",
    "    \n",
    "    \n",
    "    def reduce_and_write(self):\n",
    "        \n",
    "        df = pandas.read_csv(self.intm_file,delimiter=\";\",header=None)\n",
    "        \n",
    "        df=df.groupby(df[0]).agg(list).reset_index()\n",
    "        \n",
    "        df=df.apply(lambda x: self.io.udf_reduce(*x),axis=1)\n",
    "        \n",
    "        pandas.DataFrame(df.tolist()).to_csv(self.io.output_dir,index=False,sep=';',header=False)\n",
    "\n",
    "        \n",
    "task1=MapReduceSimple(InputTaskN1('D:\\\\Dzmitry\\\\TW','total_clicks.csv'))\n",
    "task2=MapReduceSimple(InputTaskN2('D:\\\\Dzmitry\\\\TW','filtered_clicks.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "    \n",
    "#     def testing_function (self):\n",
    "        \n",
    "#         file_name= self.in_files[0]\n",
    "        \n",
    "#         df = pandas.read_csv(file_name,delimiter=\";\",header=1)\n",
    "        \n",
    "#         df=self.io.udf_map(file_name,df)\n",
    "\n",
    "#         df.to_csv(self.intm_file,index=False,mode='a',sep=';',header=False)\n",
    "        \n",
    "#         df = pandas.read_csv(self.intm_file,delimiter=\";\",header=None)\n",
    "        \n",
    "#         df = df.groupby(df[0]).agg(list).reset_index()\n",
    "        \n",
    "#         df=df.apply(lambda x: self.io.udf_reduce(*x),axis=1)\n",
    "        \n",
    "#         pandas.DataFrame(df.tolist()).to_csv(self.io.output_dir,index=False,sep=';',header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
